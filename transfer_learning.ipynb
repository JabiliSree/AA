{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPeRRHFrMq19wR/hlGJREo0"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o2fY8zDzSfGd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#AlexNet"
      ],
      "metadata": {
        "id": "YRRFLa-fSpmO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZZRwAenS5iY",
        "outputId": "e897859e-4493-4891-9e12-22f56de2a120"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 11ms/step - accuracy: 0.8782 - loss: 0.3776 - val_accuracy: 0.9842 - val_loss: 0.0482\n",
            "Epoch 2/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - accuracy: 0.9838 - loss: 0.0536 - val_accuracy: 0.9907 - val_loss: 0.0310\n",
            "Epoch 3/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - accuracy: 0.9879 - loss: 0.0403 - val_accuracy: 0.9900 - val_loss: 0.0346\n",
            "Epoch 4/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9908 - loss: 0.0298 - val_accuracy: 0.9897 - val_loss: 0.0315\n",
            "Epoch 5/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.9922 - loss: 0.0240 - val_accuracy: 0.9913 - val_loss: 0.0283\n",
            "Epoch 6/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9940 - loss: 0.0187 - val_accuracy: 0.9917 - val_loss: 0.0267\n",
            "Epoch 7/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9956 - loss: 0.0156 - val_accuracy: 0.9903 - val_loss: 0.0380\n",
            "Epoch 8/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9955 - loss: 0.0142 - val_accuracy: 0.9932 - val_loss: 0.0268\n",
            "Epoch 9/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9958 - loss: 0.0126 - val_accuracy: 0.9924 - val_loss: 0.0261\n",
            "Epoch 10/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9968 - loss: 0.0100 - val_accuracy: 0.9920 - val_loss: 0.0361\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00       980\n",
            "           1       0.99      1.00      1.00      1135\n",
            "           2       0.99      1.00      0.99      1032\n",
            "           3       0.99      0.99      0.99      1010\n",
            "           4       1.00      0.99      0.99       982\n",
            "           5       0.98      0.99      0.99       892\n",
            "           6       0.99      1.00      0.99       958\n",
            "           7       0.99      0.99      0.99      1028\n",
            "           8       1.00      0.99      0.99       974\n",
            "           9       0.99      0.99      0.99      1009\n",
            "\n",
            "    accuracy                           0.99     10000\n",
            "   macro avg       0.99      0.99      0.99     10000\n",
            "weighted avg       0.99      0.99      0.99     10000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 974    1    0    0    0    0    4    1    0    0]\n",
            " [   0 1133    0    1    0    1    0    0    0    0]\n",
            " [   1    0 1028    0    0    0    0    3    0    0]\n",
            " [   0    0    1 1003    0    4    0    1    1    0]\n",
            " [   0    1    0    0  968    0    3    0    0   10]\n",
            " [   1    0    0    6    0  883    1    0    0    1]\n",
            " [   1    2    0    0    0    1  954    0    0    0]\n",
            " [   0    3   10    0    0    0    0 1014    0    1]\n",
            " [   0    1    3    0    0    2    0    2  965    1]\n",
            " [   0    0    0    0    3    6    1    1    0  998]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.992\n",
            "Precision: 0.9919787073688081\n",
            "Recall: 0.9919026297331783\n",
            "F1-score: 0.9919302131878374\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "img_height, img_width = 28, 28\n",
        "num_classes = 10\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "\n",
        "x_train = np.stack([x_train, x_train, x_train], axis=-1)\n",
        "x_test = np.stack([x_test, x_test, x_test], axis=-1)\n",
        "y_train_categorical = to_categorical(y_train, num_classes)\n",
        "y_test_categorical = to_categorical(y_test, num_classes)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "history = model.fit(\n",
        "    x_train, y_train_categorical,\n",
        "    epochs=10,\n",
        "    batch_size=64,\n",
        "    validation_data=(x_test, y_test_categorical)\n",
        ")\n",
        "\n",
        "\n",
        "y_pred = model.predict(x_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true = y_test\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_true, y_pred_classes))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_true, y_pred_classes))\n",
        "\n",
        "report = classification_report(y_true, y_pred_classes, output_dict=True)\n",
        "accuracy = report['accuracy']\n",
        "precision = report['macro avg']['precision']\n",
        "recall = report['macro avg']['recall']\n",
        "f1_score = report['macro avg']['f1-score']\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1-score: {f1_score}\")\n",
        "\n",
        "model.save('alexnet_mnist_model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#VGG16"
      ],
      "metadata": {
        "id": "Cb662vVJS02V"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IkgPDsG5SsWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow scikit-learn numpy\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "img_height, img_width = 32, 32\n",
        "num_classes = 10\n",
        "x_train_resized = tf.image.resize(x_train[..., np.newaxis], (img_height, img_width))\n",
        "x_train_resized = tf.repeat(x_train_resized, 3, axis=-1)\n",
        "x_test_resized = tf.image.resize(x_test[..., np.newaxis], (img_height, img_width))\n",
        "x_test_resized = tf.repeat(x_test_resized, 3, axis=-1)\n",
        "x_train_resized = x_train_resized.numpy() / 255.0\n",
        "x_test_resized = x_test_resized.numpy() / 255.0\n",
        "y_train_categorical = to_categorical(y_train, num_classes)\n",
        "y_test_categorical = to_categorical(y_test, num_classes)\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n",
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "predictions = Dense(num_classes, activation='softmax')(x)\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(\n",
        "    x_train_resized, y_train_categorical,\n",
        "    epochs=2,\n",
        "    batch_size=128,\n",
        "    validation_data=(x_test_resized, y_test_categorical)\n",
        ")\n",
        "y_pred = model.predict(x_test_resized)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true = y_test\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_true, y_pred_classes))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_true, y_pred_classes))\n",
        "report = classification_report(y_true, y_pred_classes, output_dict=True)\n",
        "accuracy = report['accuracy']\n",
        "precision = report['macro avg']['precision']\n",
        "recall = report['macro avg']['recall']\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "model.save('vgg16_mnist_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUu1hZOOTCKw",
        "outputId": "654fd4fa-00d1-4dd2-dd7d-052d3029efec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.1.24)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.70.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 1/2\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 110ms/step - accuracy: 0.9286 - loss: 0.2332 - val_accuracy: 0.9773 - val_loss: 0.0769\n",
            "Epoch 2/2\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 77ms/step - accuracy: 0.9888 - loss: 0.0391 - val_accuracy: 0.9937 - val_loss: 0.0233\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       980\n",
            "           1       1.00      1.00      1.00      1135\n",
            "           2       1.00      0.99      0.99      1032\n",
            "           3       0.99      1.00      1.00      1010\n",
            "           4       0.99      1.00      1.00       982\n",
            "           5       1.00      0.98      0.99       892\n",
            "           6       0.99      0.99      0.99       958\n",
            "           7       0.99      1.00      0.99      1028\n",
            "           8       0.99      1.00      0.99       974\n",
            "           9       0.99      0.99      0.99      1009\n",
            "\n",
            "    accuracy                           0.99     10000\n",
            "   macro avg       0.99      0.99      0.99     10000\n",
            "weighted avg       0.99      0.99      0.99     10000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 978    0    0    0    0    0    0    1    1    0]\n",
            " [   0 1131    0    0    0    0    3    1    0    0]\n",
            " [   0    0 1020    1    2    0    0    6    3    0]\n",
            " [   0    0    1 1006    0    1    0    1    1    0]\n",
            " [   0    0    0    0  981    0    0    0    0    1]\n",
            " [   1    0    0    5    0  873    2    0    3    8]\n",
            " [   3    0    1    0    0    0  950    0    2    2]\n",
            " [   0    2    0    0    0    0    0 1024    0    2]\n",
            " [   0    0    0    0    0    0    0    1  971    2]\n",
            " [   0    0    0    0    3    0    0    3    0 1003]]\n",
            "Accuracy: 0.9937\n",
            "Precision: 0.9937360277501031\n",
            "Recall: 0.9935259528139706\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ResNet"
      ],
      "metadata": {
        "id": "SgBScEo_TEvs"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LThwEZ1GSseF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Flatten, Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "img_height, img_width = 28, 28\n",
        "num_classes = 10\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "y_train_categorical = to_categorical(y_train, num_classes)\n",
        "y_test_categorical = to_categorical(y_test, num_classes)\n",
        "\n",
        "x_train = np.stack([x_train, x_train, x_train], axis=-1)\n",
        "x_test = np.stack([x_test, x_test, x_test], axis=-1)\n",
        "\n",
        "input_tensor = Input(shape=(img_height, img_width, 3))\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_tensor=input_tensor)\n",
        "\n",
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "predictions = Dense(num_classes, activation='softmax')(x)\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "    x_train, y_train_categorical,\n",
        "    epochs=10,\n",
        "    batch_size=32,\n",
        "    validation_data=(x_test, y_test_categorical)\n",
        ")\n",
        "y_pred = model.predict(x_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true = y_test\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_true, y_pred_classes))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_true, y_pred_classes))\n",
        "report = classification_report(y_true, y_pred_classes, output_dict=True)\n",
        "accuracy = report['accuracy']\n",
        "precision = report['macro avg']['precision']\n",
        "recall = report['macro avg']['recall']\n",
        "f1_score = report['macro avg']['f1-score']\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1-score: {f1_score}\")\n",
        "model.save('resnet_mnist_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBhk-fIrTCNL",
        "outputId": "42e877f5-04a4-444e-cf13-e52e15f6de2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/models/functional.py:237: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
            "Expected: ['keras_tensor']\n",
            "Received: inputs=Tensor(shape=(32, 28, 28, 3))\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.6668 - loss: 1.2139"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/models/functional.py:237: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
            "Expected: ['keras_tensor']\n",
            "Received: inputs=Tensor(shape=(None, 28, 28, 3))\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m362s\u001b[0m 186ms/step - accuracy: 0.6668 - loss: 1.2137 - val_accuracy: 0.8716 - val_loss: 0.4719\n",
            "Epoch 2/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m349s\u001b[0m 186ms/step - accuracy: 0.8568 - loss: 0.4881 - val_accuracy: 0.8986 - val_loss: 0.3608\n",
            "Epoch 3/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m381s\u001b[0m 186ms/step - accuracy: 0.8833 - loss: 0.3846 - val_accuracy: 0.9069 - val_loss: 0.3117\n",
            "Epoch 4/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m379s\u001b[0m 184ms/step - accuracy: 0.8955 - loss: 0.3405 - val_accuracy: 0.9147 - val_loss: 0.2873\n",
            "Epoch 5/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m424s\u001b[0m 206ms/step - accuracy: 0.9036 - loss: 0.3066 - val_accuracy: 0.9178 - val_loss: 0.2734\n",
            "Epoch 6/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m442s\u001b[0m 206ms/step - accuracy: 0.9150 - loss: 0.2757 - val_accuracy: 0.9257 - val_loss: 0.2500\n",
            "Epoch 7/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m444s\u001b[0m 207ms/step - accuracy: 0.9185 - loss: 0.2611 - val_accuracy: 0.9282 - val_loss: 0.2381\n",
            "Epoch 8/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m405s\u001b[0m 187ms/step - accuracy: 0.9195 - loss: 0.2542 - val_accuracy: 0.9324 - val_loss: 0.2255\n",
            "Epoch 9/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m417s\u001b[0m 206ms/step - accuracy: 0.9265 - loss: 0.2365 - val_accuracy: 0.9309 - val_loss: 0.2238\n",
            "Epoch 10/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m447s\u001b[0m 209ms/step - accuracy: 0.9290 - loss: 0.2258 - val_accuracy: 0.9356 - val_loss: 0.2127\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 159ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.96      0.97       980\n",
            "           1       0.98      1.00      0.99      1135\n",
            "           2       0.90      0.93      0.92      1032\n",
            "           3       0.89      0.95      0.92      1010\n",
            "           4       0.91      0.98      0.94       982\n",
            "           5       0.92      0.89      0.91       892\n",
            "           6       0.97      0.95      0.96       958\n",
            "           7       0.95      0.94      0.94      1028\n",
            "           8       0.89      0.89      0.89       974\n",
            "           9       0.95      0.85      0.90      1009\n",
            "\n",
            "    accuracy                           0.94     10000\n",
            "   macro avg       0.94      0.93      0.93     10000\n",
            "weighted avg       0.94      0.94      0.94     10000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 939    1   11    1    0    4    9    1   13    1]\n",
            " [   0 1131    2    0    1    0    1    0    0    0]\n",
            " [   4    2  963   24    0    8    0   12   17    2]\n",
            " [   0    2   16  958    0   13    0    9    9    3]\n",
            " [   0    2    4    0  958    1    5    1    6    5]\n",
            " [   2    3    9   45    1  797    5    3   21    6]\n",
            " [   1    3    6    2    5   16  913    0   11    1]\n",
            " [   1    5   26    5    9    2    0  965    4   11]\n",
            " [   5    0   27   24   13   17    4    2  870   12]\n",
            " [   7    6    5   12   60    9    0   23   25  862]]\n",
            "Accuracy: 0.9356\n",
            "Precision: 0.9358134530222324\n",
            "Recall: 0.9344629373605147\n",
            "F1-score: 0.9346031909588797\n"
          ]
        }
      ]
    }
  ]
}